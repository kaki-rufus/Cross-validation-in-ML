{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d714eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross_validation: get a more reliable evaluation matrix such as an accuracy_score, k-fold cross validation\n",
    "# Hyperparemeter tuning. 2 kinds of parameters: model parameter (derived from the dataset that we have) & \n",
    "# hyperparameter (determines how your model is being trained and they are changed to get the best fit of the model)\n",
    "# 2 main important techniques to work on: GridSearchCV and RandomizedSearchCV\n",
    "# Model selection\n",
    "# Accuracy and confusion matrix\n",
    "# Precision, Recall and F1 score - reliable (accuracy_score)\n",
    "# Metrix for regression (Mean Absolute Error, Mean Squared Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d69549",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation\n",
    "  - we split the dataset into \"K\" number of folds (subsets). One chunk of data is used as test data for evaluation\n",
    "  & the remaining part of the data is used for training the model. Each time, a different chunk/fold will be used as the test data\n",
    "  - The number of folds is equal to the number of iterations of data. At time, a certain chunk(s) of data is used \n",
    "  for training while the other is used for testing(evaluation)\n",
    "  - Advantage of using K-Fold to Train_Test_split is that you are testing your model with different chunks of data(iterations).\n",
    "  We have different test data for every training session hence a good one to evaluate\n",
    "  - A different instance of model is used in different iterations\n",
    "  ADVANTAGES OF K-FOLD CROSS-VALIDATION :\n",
    "  1. Better alternative for train_test split when the dataset is small. It takes a long time when dataset is large\n",
    "  2. Better for multiclass classification problems\n",
    "  3. More reliable\n",
    "  4. useful for model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd14b0",
   "metadata": {},
   "source": [
    "### 1. cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0bdcf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary dependencies\n",
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "# below class is for cross validation\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# importing the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14e410e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data or csv to pandas dataframe\n",
    "heart_data = pd.read_csv('../heart.csv')\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c5d3467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows and columns\n",
    "heart_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8605efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "heart_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c0ff6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "166bc7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking distribution of target variable\n",
    "# 1 - defective heart\n",
    "# 0 - healthy heart \n",
    "heart_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c74ffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the features and target\n",
    "X = heart_data.drop('target', axis=1)\n",
    "y = heart_data['target']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "991c25fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age : [63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 69 59 42 61 40 71 51 65 53\n",
      " 46 45 39 47 62 34 35 29 55 60 67 68 74 76 70 38 77]\n",
      "sex : [1 0]\n",
      "cp : [3 2 1 0]\n",
      "trestbps : [145 130 120 140 172 150 110 135 160 105 125 142 155 104 138 128 108 134\n",
      " 122 115 118 100 124  94 112 102 152 101 132 148 178 129 180 136 126 106\n",
      " 156 170 146 117 200 165 174 192 144 123 154 114 164]\n",
      "chol : [233 250 204 236 354 192 294 263 199 168 239 275 266 211 283 219 340 226\n",
      " 247 234 243 302 212 175 417 197 198 177 273 213 304 232 269 360 308 245\n",
      " 208 264 321 325 235 257 216 256 231 141 252 201 222 260 182 303 265 309\n",
      " 186 203 183 220 209 258 227 261 221 205 240 318 298 564 277 214 248 255\n",
      " 207 223 288 160 394 315 246 244 270 195 196 254 126 313 262 215 193 271\n",
      " 268 267 210 295 306 178 242 180 228 149 278 253 342 157 286 229 284 224\n",
      " 206 167 230 335 276 353 225 330 290 172 305 188 282 185 326 274 164 307\n",
      " 249 341 407 217 174 281 289 322 299 300 293 184 409 259 200 327 237 218\n",
      " 319 166 311 169 187 176 241 131]\n",
      "fbs : [1 0]\n",
      "restecg : [0 1 2]\n",
      "thalach : [150 187 172 178 163 148 153 173 162 174 160 139 171 144 158 114 151 161\n",
      " 179 137 157 123 152 168 140 188 125 170 165 142 180 143 182 156 115 149\n",
      " 146 175 186 185 159 130 190 132 147 154 202 166 164 184 122 169 138 111\n",
      " 145 194 131 133 155 167 192 121  96 126 105 181 116 108 129 120 112 128\n",
      " 109 113  99 177 141 136  97 127 103 124  88 195 106  95 117  71 118 134\n",
      "  90]\n",
      "exang : [0 1]\n",
      "oldpeak : [2.3 3.5 1.4 0.8 0.6 0.4 1.3 0.  0.5 1.6 1.2 0.2 1.8 1.  2.6 1.5 3.  2.4\n",
      " 0.1 1.9 4.2 1.1 2.  0.7 0.3 0.9 3.6 3.1 3.2 2.5 2.2 2.8 3.4 6.2 4.  5.6\n",
      " 2.9 2.1 3.8 4.4]\n",
      "slope : [0 2 1]\n",
      "ca : [0 2 1 3 4]\n",
      "thal : [1 2 3 0]\n",
      "target : [1 0]\n"
     ]
    }
   ],
   "source": [
    "# check unique columns\n",
    "for col in heart_data:\n",
    "    print(f'{col} : {heart_data[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6fc5203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.251142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex        cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
       "0  0.708333  1.0  1.000000  0.481132  0.244292  1.0      0.0  0.603053    0.0   \n",
       "1  0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.5  0.885496    0.0   \n",
       "2  0.250000  0.0  0.333333  0.339623  0.178082  0.0      0.0  0.770992    0.0   \n",
       "3  0.562500  1.0  0.333333  0.245283  0.251142  0.0      0.5  0.816794    0.0   \n",
       "4  0.583333  0.0  0.000000  0.245283  0.520548  0.0      0.5  0.702290    1.0   \n",
       "\n",
       "    oldpeak  slope   ca      thal  target  \n",
       "0  0.370968    0.0  0.0  0.333333     1.0  \n",
       "1  0.564516    0.0  0.0  0.666667     1.0  \n",
       "2  0.225806    1.0  0.0  0.666667     1.0  \n",
       "3  0.129032    1.0  0.0  0.666667     1.0  \n",
       "4  0.096774    1.0  0.0  0.666667     1.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale the data above \n",
    "scaler = MinMaxScaler()\n",
    "heart_data = pd.DataFrame(scaler.fit_transform(heart_data), columns=heart_data.columns)\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b5c290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique columns\n",
    "# for col in heart_data:\n",
    "#     print(f'{col} : {heart_data[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73441b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    " print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae734405",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78c2b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test data\n",
    "# use train_test_split from scikit learn\n",
    "# stratify makes the data have the same proportion i.e target data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43c30bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n",
      "(242,)\n",
      "(61, 13)\n",
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "# X_train contains all the features for the training data\n",
    "# y_train contains corresponding target\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43612329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all the models\n",
    "# Purpose is to compare the performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36d23929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of models\n",
    "models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "000632a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to fit and predict the above list of models\n",
    "def compare_models_train_test():\n",
    "    \n",
    "    for model in models:\n",
    "#         train the models\n",
    "        model.fit(X_train, y_train)\n",
    "#         evaluate the models\n",
    "        test_data_prediction = model.predict(X_test)\n",
    "#         compare true labels (y_test) and the predicted lables test_data_prediction\n",
    "        accuracy = accuracy_score(y_test, test_data_prediction)\n",
    "    \n",
    "        print(f'Accuracy score of the model {model} = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e053e6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model LogisticRegression(max_iter=1000) = 0.8688524590163934\n",
      "Accuracy score of the model SVC(kernel='linear') = 0.8688524590163934\n",
      "Accuracy score of the model KNeighborsClassifier() = 0.7049180327868853\n",
      "Accuracy score of the model RandomForestClassifier() = 0.8524590163934426\n"
     ]
    }
   ],
   "source": [
    "# call the function \n",
    "compare_models_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ba8b0",
   "metadata": {},
   "source": [
    "#### The error above is because we have not standardized some columns. Standardized each columns individually \n",
    "apart from the ones with zeros and and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e4c6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score : single function used to automatically do the splitting of data and calculate the accuracy\n",
    "# It is better than KFold since we dont have to train our data seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765709fc",
   "metadata": {},
   "source": [
    "### cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ba0b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "# cv = how many chunks/folds/iterations you want, when you use it, you automatically use the StratifiedKFold method\n",
    "# with StratifiedKFold your class distribution will be even similar to entire dataset\n",
    "# KFold data wount be stratified\n",
    "cv_score_lr = cross_val_score(LogisticRegression(max_iter=1000), X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cebff6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80327869 0.86885246 0.85245902 0.86666667 0.75      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.83"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cv_score_lr)\n",
    "\n",
    "mean_accuracy_lr = sum(cv_score_lr)/len(cv_score_lr)\n",
    "\n",
    "mean_accuracy_lr = mean_accuracy_lr * 100\n",
    "\n",
    "mean_accuracy_lr = round(mean_accuracy_lr, 2)\n",
    "\n",
    "mean_accuracy_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bda45d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81967213 0.8852459  0.80327869 0.86666667 0.76666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.83"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "cv_score_svc = cross_val_score(SVC(kernel='linear'), X, y, cv=5)\n",
    "\n",
    "print(cv_score_svc)\n",
    "\n",
    "mean_accuracy_svc = sum(cv_score_svc)/len(cv_score_svc)\n",
    "\n",
    "mean_accuracy_svc = mean_accuracy_svc * 100\n",
    "\n",
    "mean_accuracy_svc = round(mean_accuracy_svc, 2)\n",
    "\n",
    "mean_accuracy_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b4b37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one function to compare the models\n",
    "def compare_models_cross_validation():\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        cv_score = cross_val_score(model, X, y, cv = 5)\n",
    "        \n",
    "        mean_accuracy = sum(cv_score)/len(cv_score)\n",
    "        \n",
    "        mean_accuracy = mean_accuracy * 100\n",
    "        \n",
    "        mean_accuracy = round(mean_accuracy, 2)\n",
    "        \n",
    "        print(f\"Cross validation accuracies for {model} = {cv_score}\")\n",
    "        \n",
    "        print(f\"Accuracy % of the {model} {mean_accuracy}\")\n",
    "        \n",
    "        print(\"-----------------------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed73e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracies for LogisticRegression(max_iter=1000) = [0.80327869 0.86885246 0.85245902 0.86666667 0.75      ]\n",
      "Accuracy % of the LogisticRegression(max_iter=1000) 82.83\n",
      "-----------------------------------------------\n",
      "Cross validation accuracies for SVC(kernel='linear') = [0.81967213 0.8852459  0.80327869 0.86666667 0.76666667]\n",
      "Accuracy % of the SVC(kernel='linear') 82.83\n",
      "-----------------------------------------------\n",
      "Cross validation accuracies for KNeighborsClassifier() = [0.60655738 0.6557377  0.57377049 0.73333333 0.65      ]\n",
      "Accuracy % of the KNeighborsClassifier() 64.39\n",
      "-----------------------------------------------\n",
      "Cross validation accuracies for RandomForestClassifier() = [0.83606557 0.86885246 0.7704918  0.78333333 0.73333333]\n",
      "Accuracy % of the RandomForestClassifier() 79.84\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "compare_models_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa20be4b",
   "metadata": {},
   "source": [
    "### Addtional notes on cross validation techniques\n",
    "1. HoldOut validation approach -Train_test_split. Changing the random_state changes the accuracy score and may lead to \n",
    "overfitting and underfitting\n",
    "2. KFold cross validation : suppose 10 splits you decide to take, 10 splits of training and testing data will be taken\n",
    "and average mean of the splits taken. Prior to train_test_split which changes on every alter on random_state, the latter\n",
    "will take the mean of all the values received on every change of the random_state\n",
    "\n",
    "3. Stratified cross validation: used mostly when the dataset is imbalanced. It makes sure that your dataset is taken \n",
    "in almost similar proportion i.e target(dependent) and features(independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e96b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83870968 0.83870968 0.80645161 0.76666667 0.86666667 0.83333333\n",
      " 0.73333333 0.83333333 0.73333333 0.6       ]\n",
      "0.7850537634408602\n"
     ]
    }
   ],
   "source": [
    "# KFold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "model = RandomForestClassifier()\n",
    "KFold_validation = KFold(10)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "results = cross_val_score(model, X, y, cv=KFold_validation)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1a3c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81967213 0.85245902 0.80327869 0.8        0.75      ]\n",
      "0.8050819672131148\n"
     ]
    }
   ],
   "source": [
    "# StratifiedKFold cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skfold = StratifiedKFold(n_splits = 5)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=skfold)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bc893f",
   "metadata": {},
   "source": [
    "### NUMBER 2: HYPERPAREMETER TUNING\n",
    "      1. GridSearchCV\n",
    "      2. RandomizedSearchCV\n",
    "      \n",
    "      Types of parameters\n",
    "      - model parameters : parameters of the model that can be determined by training with training data. They can be\n",
    "      considered as Internal Parameters. Examples are weights and bias. The model controls these parameters and finds the best\n",
    "      out of it\n",
    "       \n",
    "       Y = m * X + b : m = slope, b = intercept.... m and b are the model parameters and the best values of it are determined\n",
    "      - Hyperparameters: parameters whose values control the learning process. They are adjustable parameters used to obtain \n",
    "      an optimal model. External Parameters. We control the hyperparameters. Examples: learning rate, Number of Epochs/iterations, n_estimators (number of decision trees you want in your model) - Random Forest\n",
    "      \n",
    "      \n",
    "      ---MACHINE LEARNING----\n",
    "      - hYPERparameter tuning (best hyperparameters) :\n",
    "            .Refers to the process of choosing the optimum set of hyperparameters for a Machine Learning Model.\n",
    "            .The process is also called Hyperparameter Optimization\n",
    "            \n",
    "            Types : GridSearchCV and RandomizedSearchCV\n",
    "                    .GridSearchCV : check a particular hyperparameter value and check which is giving us the highest accuracy\n",
    "                                 -> It finds the accuracy for all the different combinations of hyperparameter values\n",
    "                    .RandomizedSearchCV : does not calculate performance of the model for different combinations of           Hyperparameters. It only selects randomly few parameters and find which is the best value\n",
    "                                 -> Takes some random hyperparameter values and see which combination of values we are getting\n",
    "                                  high accuracy\n",
    "      - Model training (best model parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08433221",
   "metadata": {},
   "source": [
    "### Breast cancer dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All sklearn datasets are divided into data (all feature variables that help the model learn) and target (which is the actual label)\n",
    "# feature_names are the names of the feature variable: names of the columns in data\n",
    "# target_names is the name(s) of the: name of the target column\n",
    "\n",
    "\n",
    "\n",
    "# ------EXAMPLE-------\n",
    "\n",
    "# from sklearn import datasets\n",
    "\n",
    "# the load below does not return tabular data. Rather it returns a bunch\n",
    "# data = datasets.load_breast_cancer()\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# Read the DataFrame, first using the feature data\n",
    "# df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Add a target column, and fill it with the target data\n",
    "# df['target'] = data.target\n",
    "\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8847d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from sklearn\n",
    "# 1 - Benign\n",
    "# 0 - Malignant\n",
    "breast_cancer_dataset = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea2e6a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "print(breast_cancer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f18364f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data to a dataframe\n",
    "data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81a3cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the target column to the dataframe\n",
    "data_frame['label'] = breast_cancer_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "902bd0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  label  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recheck the dataset again\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba84d056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check rows and columns\n",
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d38b746a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "label                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "data_frame.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad32cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "1    357\n",
      "0    212\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check distribution of target variable\n",
    "print(data_frame.label.unique())\n",
    "print(data_frame.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f5e6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating the features and targets\n",
    "\n",
    "# feature variables\n",
    "X = data_frame.drop(columns='label', axis=1)\n",
    "\n",
    "# label\n",
    "y = data_frame['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fccb8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the above dataframes into numpy arrays\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d898fca",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "   - used for determining the best parameters for our models\n",
    "   - we'll use Support Vector Classifier Model for the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ffb2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the svc model\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db509c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C' : [1, 5, 10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66c3661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search - does the splitting of data to train and test in the background\n",
    "classifier = GridSearchCV(model, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11405347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [1, 5, 10, 20],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to our model\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af87fd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.28276463e+00, 3.20072174e-03, 4.99181747e-03, 1.21100903e-02,\n",
       "        2.44899449e+00, 3.12418938e-03, 6.24942780e-03, 6.24961853e-03,\n",
       "        3.50057569e+00, 0.00000000e+00, 6.24966621e-03, 1.56238079e-02,\n",
       "        6.46940823e+00, 4.19416428e-03, 4.19721603e-03, 1.09906673e-02]),\n",
       " 'std_fit_time': array([5.88804018e-01, 3.99171387e-04, 6.58898547e-06, 8.46580159e-03,\n",
       "        4.70833830e-01, 6.24837875e-03, 7.65395464e-03, 7.65418825e-03,\n",
       "        5.89943978e-01, 0.00000000e+00, 7.65424665e-03, 2.13248060e-07,\n",
       "        1.93078216e+00, 7.44861594e-04, 3.99541926e-04, 6.23684272e-04]),\n",
       " 'mean_score_time': array([0.0004056 , 0.00119667, 0.00220137, 0.00239844, 0.00020018,\n",
       "        0.0031249 , 0.        , 0.00312495, 0.003125  , 0.00312524,\n",
       "        0.        , 0.        , 0.00040021, 0.00059967, 0.00159945,\n",
       "        0.00239844]),\n",
       " 'std_score_time': array([0.00049676, 0.00039396, 0.0003989 , 0.00119922, 0.00040035,\n",
       "        0.00624981, 0.        , 0.0062499 , 0.00625   , 0.00625048,\n",
       "        0.        , 0.        , 0.00049016, 0.00048963, 0.0004899 ,\n",
       "        0.00048973]),\n",
       " 'param_C': masked_array(data=[1, 1, 1, 1, 5, 5, 5, 5, 10, 10, 10, 10, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'poly'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'kernel': 'linear'},\n",
       "  {'C': 5, 'kernel': 'poly'},\n",
       "  {'C': 5, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'poly'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'sigmoid'},\n",
       "  {'C': 20, 'kernel': 'linear'},\n",
       "  {'C': 20, 'kernel': 'poly'},\n",
       "  {'C': 20, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'kernel': 'sigmoid'}],\n",
       " 'split0_test_score': array([0.94736842, 0.84210526, 0.85087719, 0.54385965, 0.94736842,\n",
       "        0.88596491, 0.88596491, 0.49122807, 0.93859649, 0.88596491,\n",
       "        0.87719298, 0.48245614, 0.92982456, 0.87719298, 0.87719298,\n",
       "        0.47368421]),\n",
       " 'split1_test_score': array([0.92982456, 0.88596491, 0.89473684, 0.45614035, 0.93859649,\n",
       "        0.9122807 , 0.92982456, 0.42105263, 0.93859649, 0.92105263,\n",
       "        0.92105263, 0.40350877, 0.95614035, 0.92105263, 0.92105263,\n",
       "        0.40350877]),\n",
       " 'split2_test_score': array([0.97368421, 0.92982456, 0.92982456, 0.46491228, 0.97368421,\n",
       "        0.92105263, 0.93859649, 0.42105263, 0.97368421, 0.90350877,\n",
       "        0.9122807 , 0.42105263, 0.95614035, 0.90350877, 0.92105263,\n",
       "        0.42105263]),\n",
       " 'split3_test_score': array([0.92105263, 0.94736842, 0.94736842, 0.38596491, 0.92982456,\n",
       "        0.93859649, 0.94736842, 0.35087719, 0.94736842, 0.93859649,\n",
       "        0.95614035, 0.34210526, 0.93859649, 0.93859649, 0.94736842,\n",
       "        0.34210526]),\n",
       " 'split4_test_score': array([0.95575221, 0.9380531 , 0.9380531 , 0.45132743, 0.96460177,\n",
       "        0.95575221, 0.95575221, 0.37168142, 0.96460177, 0.95575221,\n",
       "        0.94690265, 0.36283186, 0.96460177, 0.95575221, 0.9380531 ,\n",
       "        0.3539823 ]),\n",
       " 'mean_test_score': array([0.94553641, 0.90866325, 0.91217202, 0.46044093, 0.95081509,\n",
       "        0.92272939, 0.93150132, 0.41117839, 0.95256948, 0.920975  ,\n",
       "        0.92271386, 0.40239093, 0.9490607 , 0.91922062, 0.92094395,\n",
       "        0.39886664]),\n",
       " 'std_test_score': array([0.01868869, 0.03938232, 0.03544367, 0.05025317, 0.01621632,\n",
       "        0.02368918, 0.02435811, 0.04857818, 0.01419963, 0.02470123,\n",
       "        0.02787898, 0.0489065 , 0.01281637, 0.02730027, 0.02410455,\n",
       "        0.0476401 ]),\n",
       " 'rank_test_score': array([ 4, 12, 11, 13,  2,  6,  5, 14,  1,  8,  7, 15,  3, 10,  9, 16])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "577c2c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Best parameters\n",
    "best_parameters = classifier.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c54dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525694767893185\n"
     ]
    }
   ],
   "source": [
    "# highest accuracy\n",
    "highest_accuracy = classifier.best_score_\n",
    "print(highest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2c31b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.575193</td>\n",
       "      <td>0.708650</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.945536</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.908663</td>\n",
       "      <td>0.039382</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.912172</td>\n",
       "      <td>0.035444</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023806</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.451327</td>\n",
       "      <td>0.460441</td>\n",
       "      <td>0.050253</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.026274</td>\n",
       "      <td>0.664478</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 5, 'kernel': 'linear'}</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.950815</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       1.575193      0.708650         0.001205        0.000399       1   \n",
       "1       0.006595      0.005745         0.001203        0.000399       1   \n",
       "2       0.007196      0.002638         0.004598        0.002331       1   \n",
       "3       0.023806      0.010497         0.003597        0.000489       1   \n",
       "4       3.026274      0.664478         0.000400        0.000489       5   \n",
       "\n",
       "  param_kernel                         params  split0_test_score  \\\n",
       "0       linear   {'C': 1, 'kernel': 'linear'}           0.947368   \n",
       "1         poly     {'C': 1, 'kernel': 'poly'}           0.842105   \n",
       "2          rbf      {'C': 1, 'kernel': 'rbf'}           0.850877   \n",
       "3      sigmoid  {'C': 1, 'kernel': 'sigmoid'}           0.543860   \n",
       "4       linear   {'C': 5, 'kernel': 'linear'}           0.947368   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.929825           0.973684           0.921053           0.955752   \n",
       "1           0.885965           0.929825           0.947368           0.938053   \n",
       "2           0.894737           0.929825           0.947368           0.938053   \n",
       "3           0.456140           0.464912           0.385965           0.451327   \n",
       "4           0.938596           0.973684           0.929825           0.964602   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.945536        0.018689                4  \n",
       "1         0.908663        0.039382               12  \n",
       "2         0.912172        0.035444               11  \n",
       "3         0.460441        0.050253               13  \n",
       "4         0.950815        0.016216                2  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the results to pandas dataframe\n",
    "result = pd.DataFrame(classifier.cv_results_)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc3a3ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.945536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.908663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.912172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.460441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.950815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.922729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.931501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.411178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.952569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.920975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.922714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.402391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.949061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.919221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.920944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.398867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_kernel  mean_test_score\n",
       "0        1       linear         0.945536\n",
       "1        1         poly         0.908663\n",
       "2        1          rbf         0.912172\n",
       "3        1      sigmoid         0.460441\n",
       "4        5       linear         0.950815\n",
       "5        5         poly         0.922729\n",
       "6        5          rbf         0.931501\n",
       "7        5      sigmoid         0.411178\n",
       "8       10       linear         0.952569\n",
       "9       10         poly         0.920975\n",
       "10      10          rbf         0.922714\n",
       "11      10      sigmoid         0.402391\n",
       "12      20       linear         0.949061\n",
       "13      20         poly         0.919221\n",
       "14      20          rbf         0.920944\n",
       "15      20      sigmoid         0.398867"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_result = result[['param_C', 'param_kernel', 'mean_test_score']]\n",
    "grid_search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ea421",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0130b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading SVC model\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec4d2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C' : [1, 5, 10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf7954a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized search\n",
    "classifier = RandomizedSearchCV(model, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e92cfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SVC(),\n",
       "                   param_distributions={'C': [1, 5, 10, 20],\n",
       "                                        'kernel': ['linear', 'poly', 'rbf',\n",
       "                                                   'sigmoid']})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit our data to our model\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0513e39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.05476685, 0.00579596, 3.20612097, 0.01519241, 0.00399799,\n",
       "        0.00479684, 0.0047956 , 0.00834093, 0.01228509, 1.63752623]),\n",
       " 'std_fit_time': array([9.25655918e-02, 1.83115019e-03, 8.48961436e-01, 5.07117744e-03,\n",
       "        1.19113884e-06, 1.32681367e-03, 1.16586264e-03, 4.75746093e-03,\n",
       "        1.16418940e-03, 6.62028887e-01]),\n",
       " 'mean_score_time': array([0.00699511, 0.00139928, 0.00080023, 0.00539613, 0.00240035,\n",
       "        0.00220032, 0.00220113, 0.00219784, 0.00415587, 0.00100021]),\n",
       " 'std_score_time': array([0.00460176, 0.0004892 , 0.00040011, 0.0023342 , 0.00280263,\n",
       "        0.00040116, 0.00098409, 0.00040026, 0.0033435 , 0.00063226]),\n",
       " 'param_kernel': masked_array(data=['rbf', 'poly', 'linear', 'sigmoid', 'poly', 'rbf',\n",
       "                    'rbf', 'rbf', 'sigmoid', 'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_C': masked_array(data=[10, 10, 5, 10, 20, 20, 5, 1, 5, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'kernel': 'rbf', 'C': 10},\n",
       "  {'kernel': 'poly', 'C': 10},\n",
       "  {'kernel': 'linear', 'C': 5},\n",
       "  {'kernel': 'sigmoid', 'C': 10},\n",
       "  {'kernel': 'poly', 'C': 20},\n",
       "  {'kernel': 'rbf', 'C': 20},\n",
       "  {'kernel': 'rbf', 'C': 5},\n",
       "  {'kernel': 'rbf', 'C': 1},\n",
       "  {'kernel': 'sigmoid', 'C': 5},\n",
       "  {'kernel': 'linear', 'C': 1}],\n",
       " 'split0_test_score': array([0.87719298, 0.88596491, 0.94736842, 0.48245614, 0.87719298,\n",
       "        0.87719298, 0.88596491, 0.85087719, 0.49122807, 0.94736842]),\n",
       " 'split1_test_score': array([0.92105263, 0.92105263, 0.93859649, 0.40350877, 0.92105263,\n",
       "        0.92105263, 0.92982456, 0.89473684, 0.42105263, 0.92982456]),\n",
       " 'split2_test_score': array([0.9122807 , 0.90350877, 0.97368421, 0.42105263, 0.90350877,\n",
       "        0.92105263, 0.93859649, 0.92982456, 0.42105263, 0.97368421]),\n",
       " 'split3_test_score': array([0.95614035, 0.93859649, 0.92982456, 0.34210526, 0.93859649,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.35087719, 0.92105263]),\n",
       " 'split4_test_score': array([0.94690265, 0.95575221, 0.96460177, 0.36283186, 0.95575221,\n",
       "        0.9380531 , 0.95575221, 0.9380531 , 0.37168142, 0.95575221]),\n",
       " 'mean_test_score': array([0.92271386, 0.920975  , 0.95081509, 0.40239093, 0.91922062,\n",
       "        0.92094395, 0.93150132, 0.91217202, 0.41117839, 0.94553641]),\n",
       " 'std_test_score': array([0.02787898, 0.02470123, 0.01621632, 0.0489065 , 0.02730027,\n",
       "        0.02410455, 0.02435811, 0.03544367, 0.04857818, 0.01868869]),\n",
       " 'rank_test_score': array([ 4,  5,  1, 10,  7,  6,  3,  8,  9,  2])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the classifier results/cross validation results\n",
    "classifier.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "684096ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters that are determined by RandomizedSearchCV\n",
    "best_paramaters = classifier.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee8b6cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9508150908244062"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print highest accuracy achieved\n",
    "best_accuracy = classifier.best_score_\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c15a3a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054767</td>\n",
       "      <td>0.092566</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 10}</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.922714</td>\n",
       "      <td>0.027879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>poly</td>\n",
       "      <td>10</td>\n",
       "      <td>{'kernel': 'poly', 'C': 10}</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.920975</td>\n",
       "      <td>0.024701</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.206121</td>\n",
       "      <td>0.848961</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>linear</td>\n",
       "      <td>5</td>\n",
       "      <td>{'kernel': 'linear', 'C': 5}</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.950815</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015192</td>\n",
       "      <td>0.005071</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>{'kernel': 'sigmoid', 'C': 10}</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.362832</td>\n",
       "      <td>0.402391</td>\n",
       "      <td>0.048906</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>poly</td>\n",
       "      <td>20</td>\n",
       "      <td>{'kernel': 'poly', 'C': 20}</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.919221</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_kernel  \\\n",
       "0       0.054767      0.092566         0.006995        0.004602          rbf   \n",
       "1       0.005796      0.001831         0.001399        0.000489         poly   \n",
       "2       3.206121      0.848961         0.000800        0.000400       linear   \n",
       "3       0.015192      0.005071         0.005396        0.002334      sigmoid   \n",
       "4       0.003998      0.000001         0.002400        0.002803         poly   \n",
       "\n",
       "  param_C                          params  split0_test_score  \\\n",
       "0      10      {'kernel': 'rbf', 'C': 10}           0.877193   \n",
       "1      10     {'kernel': 'poly', 'C': 10}           0.885965   \n",
       "2       5    {'kernel': 'linear', 'C': 5}           0.947368   \n",
       "3      10  {'kernel': 'sigmoid', 'C': 10}           0.482456   \n",
       "4      20     {'kernel': 'poly', 'C': 20}           0.877193   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.921053           0.912281           0.956140           0.946903   \n",
       "1           0.921053           0.903509           0.938596           0.955752   \n",
       "2           0.938596           0.973684           0.929825           0.964602   \n",
       "3           0.403509           0.421053           0.342105           0.362832   \n",
       "4           0.921053           0.903509           0.938596           0.955752   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.922714        0.027879                4  \n",
       "1         0.920975        0.024701                5  \n",
       "2         0.950815        0.016216                1  \n",
       "3         0.402391        0.048906               10  \n",
       "4         0.919221        0.027300                7  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(classifier.cv_results_)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03945fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.922714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.920975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.950815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.402391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.919221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.920944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.931501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.912172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.411178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.945536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0      10          rbf         0.922714\n",
       "1      10         poly         0.920975\n",
       "2       5       linear         0.950815\n",
       "3      10      sigmoid         0.402391\n",
       "4      20         poly         0.919221\n",
       "5      20          rbf         0.920944\n",
       "6       5          rbf         0.931501\n",
       "7       1          rbf         0.912172\n",
       "8       5      sigmoid         0.411178\n",
       "9       1       linear         0.945536"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search_result = result[['param_C', 'param_kernel', 'mean_test_score']]\n",
    "randomized_search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7573c1",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "------process of choosing the best suited model for a particular problem\n",
    "------selecting a model depends on various factors such as dataset, task, nature of model etc\n",
    "\n",
    "TWO FACTOS TO BE CONSIDERED:\n",
    "    - Logical reason to select a model\n",
    "    - Comparing the performance of the model\n",
    "MODELS CAN BE SELECTED BASED ON:\n",
    "\n",
    "    1. Type of data available\n",
    "       - Images and videos : CNN (Convolutional neural network) which is a type of artificial neural network used in image\n",
    "                             recognition and processing specifically designed to process pixel data\n",
    "                             \n",
    "       - Text data or Speech data : RNN (Recurrent Neural Network) which uses sequential data or time series data\n",
    "       \n",
    "                      -----------THE ABOVE TWO ARE FOR DEEP LEARNING ----------------------------\n",
    "                      \n",
    "       - Numerical data : SVM, Logistic Regression, Decision trees etc -- MACHINE LEARNING MODELS --\n",
    "       \n",
    "       \n",
    "    2. Based on the task we need to carry out\n",
    "       -  Classification tasks : SVM, Logistic Regression, Decision Trees, RandomForestClassifier etc \n",
    "            . Logistic Regression : (used for binary classification problems): Easy to implement, performs well on data \n",
    "                                  with linear relationships, less prone to overfitting for low dimensional datasets\n",
    "                                  \n",
    "                                  -High dimensional datasets causes overfitting, difficult to capture complex relationships\n",
    "                                   in a dataset, sensitive to outliers, Needs a larger dataset\n",
    "                                   \n",
    "            . Decision tree : can be used for both classification and regression, easy to interpret, no need for \n",
    "                             normalization or scaling, not sensitive to outliers\n",
    "                             \n",
    "                             : overfitting issue, instability, training time is relatively high\n",
    "            \n",
    "            \n",
    "            . SVM : used when you know several number of columns in your datasets\n",
    "         \n",
    "       - Regression tasks : Linear Regression, Random Forest, Polynomial Regression\n",
    "                     . Linear Regression : performs well on data with linear relationships, It's sensitive to \n",
    "                                          to outliers, underfitting issue\n",
    "       \n",
    "       - Clustering tasks : K-Means Clustering, Hierarchical clustering  (UNSUPERVISED LEARNING TECHNIQUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e180fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the models with default hyperparameter values using Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a07965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models\n",
    "# max_iter used because we not standardizing the data\n",
    "model = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier(random_state=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd1de746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_using_cross_validation():\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        cv_score = cross_val_score(model, X, y, cv=5)\n",
    "        \n",
    "        mean_accuracy = np.mean(cv_score)*100\n",
    "        \n",
    "        mean_accuracy = round(mean_accuracy, 2)\n",
    "        \n",
    "        print(f'Cross Validation for {model} = {cv_score}')\n",
    "        print(f'Accuracy score of {model} : {mean_accuracy}')\n",
    "        print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6947aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation for LogisticRegression(max_iter=1000) = [0.93859649 0.93859649 0.97368421 0.94736842 0.96460177]\n",
      "Accuracy score of LogisticRegression(max_iter=1000) : 95.26\n",
      "-----------------------------------------------\n",
      "Cross Validation for SVC(kernel='linear') = [0.94736842 0.92982456 0.97368421 0.92105263 0.95575221]\n",
      "Accuracy score of SVC(kernel='linear') : 94.55\n",
      "-----------------------------------------------\n",
      "Cross Validation for KNeighborsClassifier() = [0.88596491 0.93859649 0.93859649 0.94736842 0.92920354]\n",
      "Accuracy score of KNeighborsClassifier() : 92.79\n",
      "-----------------------------------------------\n",
      "Cross Validation for RandomForestClassifier() = [0.93859649 0.94736842 0.98245614 0.97368421 0.97345133]\n",
      "Accuracy score of RandomForestClassifier() : 96.31\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "compare_models_using_cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509021a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
